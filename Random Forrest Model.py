# -*- coding: utf-8 -*-
"""RF-based.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CwOEOttw6iZuD8bGPAzFNZd7ZDrHqoCa
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt

# Load the data with the specified file path
data = pd.read_excel('all-50m.xlsx')
e=300
#e=0.078
#e=0.3721
#e=0.457
# Check how many rows have PM2.5 > 300
high_pm25_count = (data["PM2.5"] > e).sum()
print(f"Number of rows with PM2.5 > 300: {high_pm25_count}")

# Remove rows where PM2.5 > 300
data = data[data["PM2.5"] <= e]

# Define features and target variable
features = [
'Fixed',"Avg_Visibility", "Ambient Temperature °C", "Total - Office - 150", "Total - Office - 50", "Dis-From - fuel - 0","Ambient Humidity %RH","Avg_Dew_Point",
                    "Avg_Wind", 'Season',"Dis-From - subway - 0"
]
features = [col for col in features if col in data.columns]

# Include all columns except the excluded ones
#features = [col for col in data.columns if col not in excluded_columns]

# Define target variable
target = "PM2.5"

# Fill NaN values with 0
data = data.fillna(0)

# Define features (X) and target (y)
X = data[features]
y = data[target]

# 80/20 Train-Test Split
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X, y, test_size=0.2, random_state=42)
simple_rf = RandomForestRegressor(random_state=42)
simple_rf.fit(X_train_split, y_train_split)
y_pred_split = simple_rf.predict(X_test_split)
print("80/20 Split - R2:", r2_score(y_test_split, y_pred_split))
print("80/20 Split - RMSE:", np.sqrt(mean_squared_error(y_test_split, y_pred_split)))

# GridSearchCV for Hyperparameter Tuning
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

grid_search = GridSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_grid=param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train_split, y_train_split)

print("Best parameters from GridSearchCV:", grid_search.best_params_)
print("Best CV R2 score from GridSearchCV:", grid_search.best_score_)

best_rf = grid_search.best_estimator_
y_pred_best = best_rf.predict(X_test_split)
print("R2 (best model on test):", r2_score(y_test_split, y_pred_best))
print("RMSE (best model on test):", np.sqrt(mean_squared_error(y_test_split, y_pred_best)))

# SHAP Analysis
import shap

explainer = shap.TreeExplainer(best_rf)
shap_values = explainer.shap_values(X_test_split)

# Bar plot
shap.summary_plot(shap_values, X_test_split, plot_type="bar", show=False)
plt.savefig("shap_feature_importance_bar.png", bbox_inches="tight")
plt.close()

# Full summary plot
shap.summary_plot(shap_values, X_test_split, show=False)
plt.savefig("shap_summary_plot.png", bbox_inches="tight")
plt.close()

print("SHAP plots saved as 'shap_feature_importance_bar.png' and 'shap_summary_plot.png'")

# Initialize Random Forest Regressor
model = RandomForestRegressor(random_state=42)

# 10-Fold Cross-Validation
kf = KFold(n_splits=10, shuffle=True, random_state=42)

# Store results to save later in DataFrame
all_results = []

# Store R2 scores for all folds
scores = cross_val_score(model, X, y, cv=kf, scoring='r2')
mean_r2_cv = scores.mean()

print("Mean R² score (10-Fold Cross-Validation):", mean_r2_cv)

# Visualizing Cross-Validation Results
predicted = []
actual = []

for train_index, test_index in kf.split(X):
    X_train_kf, X_test_kf = X.iloc[train_index], X.iloc[test_index]
    y_train_kf, y_test_kf = y.iloc[train_index], y.iloc[test_index]

    # Train the model
    model.fit(X_train_kf, y_train_kf)

    # Predict
    y_pred = model.predict(X_test_kf)

  # Store the results (Route, Points_id, Actual, Predicted)
    '''
    fold_results = pd.DataFrame({
        'Route': data.iloc[test_index]['Route'],
        'Points_id': data.iloc[test_index]['Points_id'],
        'Actual_PM2.5': y_test_kf,
        'Predicted_PM2.5': y_pred
    })
    '''
    fold_results = pd.DataFrame({
    'Route': data.iloc[test_index]['Route'].values,  # Convert to array
    'Points_id': data.iloc[test_index]['Points_id'].values,  # Convert to array
    'Actual_PM2.5': y_test_kf.values,  # Convert to array
    'Season': data.iloc[test_index]['Season'].values,
    'Predicted_PM2.5': y_pred  # Should be already an array
})
    all_results.append(fold_results)

    # Append actual and predicted values for plotting
    predicted.extend(y_pred)
    actual.extend(y_test_kf)

# Combine all results from each fold
final_results = pd.concat(all_results, axis=0)

# Save the results to an Excel file
final_results.to_excel('RF_all-50m-predicted_vs_actual_10fold_results.xlsx', index=False)

# Visualize the results (Actual vs Predicted)
plt.figure(figsize=(10, 6))
plt.scatter(actual, predicted, alpha=0.6, color="b")
plt.plot([min(actual), max(actual)], [min(actual), max(actual)], color="red", linestyle="--", label="Ideal Fit")
plt.xlabel("Actual PM2.5")
plt.ylabel("Predicted PM2.5")
plt.title("Actual vs Predicted PM2.5 (10-Fold Cross-Validation)")
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd

# Get feature importances from the trained model
feature_importances = model.feature_importances_

# Create a DataFrame to display features and their importance scores
importance_df = pd.DataFrame({
    'Feature': features,
    'Importance': feature_importances
})

# Sort the features by their importance in descending order
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Display the top 10 most important features
top_10_features = importance_df.head(10)
print("Top 10 Features Contributing the Most to Prediction:")
print(top_10_features)

# Save the top 10 features to an Excel file
top_10_features.to_excel("RF_all-50m_features_importance.xlsx", index=False)

print(".xlsx'")

from sklearn.model_selection import RepeatedKFold
from sklearn.ensemble import RandomForestRegressor
import numpy as np
from sklearn.metrics import r2_score

# Set up the Repeated K-Fold Cross-Validation
repeated_kf = RepeatedKFold(n_splits=10, n_repeats=100, random_state=42)

# Initialize Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42)

# Store R2 scores and RMSE values for all folds
all_r2_scores_rf = []
all_rmse_scores_rf = []

# Perform Repeated K-Fold Cross-Validation
for train_index, test_index in repeated_kf.split(X):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    # Train the model
    rf_model.fit(X_train, y_train)

    # Predict
    y_pred = rf_model.predict(X_test)

    # R2 score
    r2 = r2_score(y_test, y_pred)
    all_r2_scores_rf.append(r2)

    # RMSE Calculation (Manually)
    rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))
    all_rmse_scores_rf.append(rmse)

# Calculate mean and std of R2 scores
mean_r2_rf = np.mean(all_r2_scores_rf)
std_r2_rf = np.std(all_r2_scores_rf)

# Calculate mean and std of RMSE scores
mean_rmse_rf = np.mean(all_rmse_scores_rf)
std_rmse_rf = np.std(all_rmse_scores_rf)

# Output the results
print(f"Random Forest - Mean R² score (Repeated K-Fold CV): {mean_r2_rf:.4f}")
print(f"Random Forest - Standard Deviation of R² scores: {std_r2_rf:.4f}")
print(f"Random Forest - Mean RMSE score: {mean_rmse_rf:.4f}")
print(f"Random Forest - Standard Deviation of RMSE scores: {std_rmse_rf:.4f}")